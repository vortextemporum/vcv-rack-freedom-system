#include "PluginProcessor.h"
#include "PluginEditor.h"

juce::AudioProcessorValueTreeState::ParameterLayout FlutterVerbAudioProcessor::createParameterLayout()
{
    juce::AudioProcessorValueTreeState::ParameterLayout layout;

    // SIZE - Room dimensions
    layout.add(std::make_unique<juce::AudioParameterFloat>(
        juce::ParameterID { "SIZE", 1 },
        "Size",
        juce::NormalisableRange<float>(0.0f, 100.0f, 0.1f, 1.0f),
        50.0f,
        "%"
    ));

    // DECAY - Reverb tail length
    layout.add(std::make_unique<juce::AudioParameterFloat>(
        juce::ParameterID { "DECAY", 1 },
        "Decay",
        juce::NormalisableRange<float>(0.1f, 10.0f, 0.01f, 1.0f),
        2.5f,
        "s"
    ));

    // MIX - Dry/wet blend
    layout.add(std::make_unique<juce::AudioParameterFloat>(
        juce::ParameterID { "MIX", 1 },
        "Mix",
        juce::NormalisableRange<float>(0.0f, 100.0f, 0.1f, 1.0f),
        25.0f,
        "%"
    ));

    // AGE - Tape character intensity
    layout.add(std::make_unique<juce::AudioParameterFloat>(
        juce::ParameterID { "AGE", 1 },
        "Age",
        juce::NormalisableRange<float>(0.0f, 100.0f, 0.1f, 1.0f),
        20.0f,
        "%"
    ));

    // DRIVE - Tape saturation
    layout.add(std::make_unique<juce::AudioParameterFloat>(
        juce::ParameterID { "DRIVE", 1 },
        "Drive",
        juce::NormalisableRange<float>(0.0f, 100.0f, 0.1f, 1.0f),
        20.0f,
        "%"
    ));

    // TONE - DJ-style filter
    layout.add(std::make_unique<juce::AudioParameterFloat>(
        juce::ParameterID { "TONE", 1 },
        "Tone",
        juce::NormalisableRange<float>(-100.0f, 100.0f, 0.1f, 1.0f),
        0.0f,
        ""
    ));

    // MOD_MODE - Modulation routing
    layout.add(std::make_unique<juce::AudioParameterBool>(
        juce::ParameterID { "MOD_MODE", 1 },
        "Mod Mode",
        false  // Default: WET ONLY (0)
    ));

    return layout;
}

FlutterVerbAudioProcessor::FlutterVerbAudioProcessor()
    : AudioProcessor(BusesProperties()
                        .withInput("Input", juce::AudioChannelSet::stereo(), true)
                        .withOutput("Output", juce::AudioChannelSet::stereo(), true))
    , parameters(*this, nullptr, "Parameters", createParameterLayout())
{
}

FlutterVerbAudioProcessor::~FlutterVerbAudioProcessor()
{
}

void FlutterVerbAudioProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    // Store sample rate for LFO calculations
    currentSampleRate = sampleRate;

    // Prepare DSP spec
    spec.sampleRate = sampleRate;
    spec.maximumBlockSize = static_cast<juce::uint32>(samplesPerBlock);
    spec.numChannels = static_cast<juce::uint32>(getTotalNumOutputChannels());

    // Phase 4.1: Prepare core reverb processing components
    dryWetMixer.prepare(spec);
    dryWetMixer.reset();

    // Prepare reverb with ProcessSpec
    reverb.prepare(spec);
    reverb.reset();

    // Phase 4.2: Prepare modulation system
    modulationDelay.prepare(spec);
    modulationDelay.reset();
    modulationDelay.setMaximumDelayInSamples(static_cast<int>(sampleRate * 0.2)); // 200ms max

    // Initialize per-channel LFO phase tracking
    wowPhase.resize(spec.numChannels, 0.0f);
    flutterPhase.resize(spec.numChannels, 0.0f);
}

void FlutterVerbAudioProcessor::releaseResources()
{
    // DSP cleanup will be added in Stage 4
}

void FlutterVerbAudioProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)
{
    juce::ScopedNoDenormals noDenormals;
    juce::ignoreUnused(midiMessages);

    // Clear unused channels
    for (int i = getTotalNumInputChannels(); i < getTotalNumOutputChannels(); ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    // Phase 4.1: Read SIZE, DECAY, MIX parameters (atomic, real-time safe)
    auto* sizeParam = parameters.getRawParameterValue("SIZE");
    auto* decayParam = parameters.getRawParameterValue("DECAY");
    auto* mixParam = parameters.getRawParameterValue("MIX");

    float sizeValue = sizeParam->load() / 100.0f;  // 0-100% → 0.0-1.0
    float decayValue = decayParam->load();          // 0.1-10.0 seconds
    float mixValue = mixParam->load() / 100.0f;     // 0-100% → 0.0-1.0

    // Phase 4.2: Read AGE parameter for modulation depth
    auto* ageParam = parameters.getRawParameterValue("AGE");
    float ageValue = ageParam->load() / 100.0f;  // 0-100% → 0.0-1.0

    // Configure reverb parameters
    juce::Reverb::Parameters reverbParams;
    reverbParams.roomSize = sizeValue;

    // Map decay time to damping (inverse relationship)
    // Short decay → high damping, long decay → low damping
    // Empirical mapping: decay 0.1s → damping 0.9, decay 10s → damping 0.1
    reverbParams.damping = juce::jmap(decayValue, 0.1f, 10.0f, 0.9f, 0.1f);

    reverbParams.width = 1.0f;         // Full stereo
    reverbParams.freezeMode = 0.0f;    // No freeze
    reverbParams.wetLevel = 1.0f;      // Full wet (mixer handles blend)
    reverbParams.dryLevel = 0.0f;      // No dry (mixer handles blend)

    reverb.setParameters(reverbParams);

    // Set dry/wet mix proportion
    dryWetMixer.setWetMixProportion(mixValue);

    // Process audio with DSP pipeline
    juce::dsp::AudioBlock<float> block(buffer);

    // Push dry samples before processing
    dryWetMixer.pushDrySamples(block);

    // Process reverb using modern DSP API
    juce::dsp::ProcessContextReplacing<float> context(block);
    reverb.process(context);

    // Phase 4.2: Apply modulation to reverb output (before dry/wet mixer)
    if (ageValue > 0.0f)  // Only apply modulation if AGE > 0
    {
        const int numChannels = buffer.getNumChannels();
        const int numSamples = buffer.getNumSamples();

        // LFO configuration
        const float wowFreqHz = 1.0f;      // Center frequency: 1Hz (range 0.5-1.5Hz)
        const float flutterFreqHz = 6.0f;  // Center frequency: 6Hz (range 4-8Hz)
        const float baseDelayMs = 50.0f;   // Base delay: 50ms
        const float maxModDepth = 0.2f;    // ±20% at AGE=100%

        // Calculate phase increments (radians per sample)
        const float wowPhaseInc = (wowFreqHz * 2.0f * juce::MathConstants<float>::pi) / static_cast<float>(currentSampleRate);
        const float flutterPhaseInc = (flutterFreqHz * 2.0f * juce::MathConstants<float>::pi) / static_cast<float>(currentSampleRate);

        // Process each channel
        for (int channel = 0; channel < numChannels; ++channel)
        {
            auto* channelData = buffer.getWritePointer(channel);

            for (int sample = 0; sample < numSamples; ++sample)
            {
                // Calculate wow LFO output (sine wave)
                float wowOutput = std::sin(wowPhase[channel]);

                // Calculate flutter LFO output (sine wave)
                float flutterOutput = std::sin(flutterPhase[channel]);

                // Combine modulation signals (both contribute to pitch variation)
                float totalModulation = (wowOutput + flutterOutput) * 0.5f;  // Average to keep in ±1.0 range

                // Scale by AGE parameter
                totalModulation *= ageValue;

                // Calculate modulated delay time in samples
                float baseDelaySamples = (baseDelayMs / 1000.0f) * static_cast<float>(currentSampleRate);
                float modulationAmount = baseDelaySamples * maxModDepth * totalModulation;  // ±20% depth
                float delayTimeSamples = baseDelaySamples + modulationAmount;

                // Ensure delay time is within valid range
                delayTimeSamples = juce::jlimit(1.0f, static_cast<float>(currentSampleRate * 0.2), delayTimeSamples);

                // Set delay time for this channel
                modulationDelay.setDelay(static_cast<float>(delayTimeSamples));

                // Process sample through delay line
                modulationDelay.pushSample(channel, channelData[sample]);
                channelData[sample] = modulationDelay.popSample(channel);

                // Update LFO phases with wrapping
                wowPhase[channel] += wowPhaseInc;
                if (wowPhase[channel] >= 2.0f * juce::MathConstants<float>::pi)
                    wowPhase[channel] -= 2.0f * juce::MathConstants<float>::pi;

                flutterPhase[channel] += flutterPhaseInc;
                if (flutterPhase[channel] >= 2.0f * juce::MathConstants<float>::pi)
                    flutterPhase[channel] -= 2.0f * juce::MathConstants<float>::pi;
            }
        }
    }

    // Mix dry and wet samples
    dryWetMixer.mixWetSamples(block);
}

juce::AudioProcessorEditor* FlutterVerbAudioProcessor::createEditor()
{
    return new FlutterVerbAudioProcessorEditor(*this);
}

void FlutterVerbAudioProcessor::getStateInformation(juce::MemoryBlock& destData)
{
    auto state = parameters.copyState();
    std::unique_ptr<juce::XmlElement> xml(state.createXml());
    copyXmlToBinary(*xml, destData);
}

void FlutterVerbAudioProcessor::setStateInformation(const void* data, int sizeInBytes)
{
    std::unique_ptr<juce::XmlElement> xmlState(getXmlFromBinary(data, sizeInBytes));

    if (xmlState != nullptr && xmlState->hasTagName(parameters.state.getType()))
        parameters.replaceState(juce::ValueTree::fromXml(*xmlState));
}

// Factory function
juce::AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
    return new FlutterVerbAudioProcessor();
}
